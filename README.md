# rock-paper-scissors-cnn
ðŸª¨ðŸ“„âœ‚ï¸ Rock Paper Scissors Detector using CNN & Webcam

This project is a real-time Rock-Paper-Scissors (RPS) hand gesture classifier built using PyTorch, OpenCV, and a Convolutional Neural Network (CNN). The model is trained on a custom image dataset containing hand gestures for rock, paper, and scissors, and it uses your computer's webcam to recognize hand signs in live video.

ðŸ” What it Does
  -  Trains a CNN model on grayscale, normalized 28Ã—28 images of hand gestures.
  -  Tests the trained model to evaluate its performance.
  -  Activates your webcam and detects RPS gestures from a live video feed in a central rectangular Region of Interest (ROI).
  -  Displays the predicted label ("Rock", "Paper", or "Scissors") in real-time.
    
ðŸ“¦ Features
  -  ðŸ” Real-Time Prediction using webcam feed.
  -  ðŸ§  Custom CNN Model with two convolutional layers.
  -  ðŸ“‰ Training & Evaluation on a labeled image dataset.
  -  ðŸ’» User-Friendly interface via OpenCV display window.
  -  ðŸŽ¨ ROI (Region of Interest) centered for consistent classification.
    
ðŸ§  Technologies Used
  -  PyTorch: Model building and training
  -  Torchvision: Image preprocessing and dataset handling
  -  OpenCV: Webcam capture and live visualization
  -  PIL: Image format conversion for preprocessing
  -  Rock Paper Scissors image dataset can be found here --> https://www.kaggle.com/datasets/drgfreeman/rockpaperscissors


